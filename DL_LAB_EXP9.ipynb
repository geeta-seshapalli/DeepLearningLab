{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIZA0mJFSRZydaxTo5WJIe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Download GloVe embeddings (this will take a minute or two)\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","\n","# Unzip the downloaded file\n","!unzip -q glove.6B.zip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaXBsUoW8xR7","executionInfo":{"status":"ok","timestamp":1745165355985,"user_tz":-330,"elapsed":188269,"user":{"displayName":"Geeta Krishnaveni Seshapalli","userId":"03567840691782124226"}},"outputId":"91b9feea-63df-4bd4-d70d-3e6d0c22c19d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-04-20 16:06:08--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2025-04-20 16:06:08--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2025-04-20 16:06:08--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: â€˜glove.6B.zipâ€™\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    in 2m 39s  \n","\n","2025-04-20 16:08:47 (5.19 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAN_Jtv88gg2","executionInfo":{"status":"ok","timestamp":1745165103251,"user_tz":-330,"elapsed":4971,"user":{"displayName":"Geeta Krishnaveni Seshapalli","userId":"03567840691782124226"}},"outputId":"f109253e-8e8d-4c8e-cf56-312e9aabceed"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.14.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import emoji\n","\n","# Sample dataset\n","X_train = np.array([\"I love you\", \"I hate you\", \"I am so happy\", \"I am sad\", \"You are amazing\"])\n","Y_train = np.array([0, 1, 2, 3, 2])  # 0: â¤ï¸, 1: ðŸ˜ , 2: ðŸ˜„, 3: ðŸ˜¢\n","\n","X_test = np.array([\"You make me smile\", \"I am heartbroken\"])\n","Y_test = np.array([2, 3])\n","\n","# Emoji dictionary\n","emoji_dict = {0: \"â¤ï¸\", 1: \"ðŸ˜ \", 2: \"ðŸ˜„\", 3: \"ðŸ˜¢\"}\n","\n","# Load GloVe embeddings\n","def load_glove_embeddings(file_path=\"glove.6B.50d.txt\"):\n","    print(\"Loading GloVe word vectors...\")\n","    embeddings_index = {}\n","    with open(file_path, encoding=\"utf8\") as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype=\"float32\")\n","            embeddings_index[word] = coefs\n","    print(f\"Loaded {len(embeddings_index)} word vectors.\")\n","    return embeddings_index\n","\n","# Convert sentence to average word vector\n","def sentence_to_avg(sentence, word_to_vec_map):\n","    words = sentence.lower().split()\n","    avg = np.zeros((50,))\n","    count = 0\n","    for w in words:\n","        if w in word_to_vec_map:\n","            avg += word_to_vec_map[w]\n","            count += 1\n","    if count > 0:\n","        avg /= count\n","    return avg\n","\n","# Load GloVe\n","word_to_vec_map = load_glove_embeddings()\n","\n","# Vectorize dataset\n","X_train_avg = np.array([sentence_to_avg(s, word_to_vec_map) for s in X_train])\n","X_test_avg = np.array([sentence_to_avg(s, word_to_vec_map) for s in X_test])\n","\n","# Train model\n","clf = LogisticRegression(max_iter=1000)\n","clf.fit(X_train_avg, Y_train)\n","\n","# Predict and print results\n","Y_pred = clf.predict(X_test_avg)\n","print(\"\\nPredictions:\")\n","for i, sent in enumerate(X_test):\n","    print(f\"{sent} => {emoji_dict[Y_pred[i]]}\")\n","\n","# Evaluate\n","print(\"\\nAccuracy:\", accuracy_score(Y_test, Y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aX18cZKJ9T93","executionInfo":{"status":"ok","timestamp":1745165369633,"user_tz":-330,"elapsed":6572,"user":{"displayName":"Geeta Krishnaveni Seshapalli","userId":"03567840691782124226"}},"outputId":"7953362c-e7d9-4497-c1ef-22b9968eb74c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading GloVe word vectors...\n","Loaded 400000 word vectors.\n","\n","Predictions:\n","You make me smile => ðŸ˜„\n","I am heartbroken => ðŸ˜¢\n","\n","Accuracy: 1.0\n","Confusion Matrix:\n"," [[1 0]\n"," [0 1]]\n"]}]}]}